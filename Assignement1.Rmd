---
title: "Assignment 1: MATH 4753"
author: "Eid Zaben"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
    theme: spacelab
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 15/15 Questions Solved

# Questions

## Question 1

This course has no curves and the final grades for this course are as follows:

A: >= 90%

B: >= 80% and < 90%

C:  >= 60% and < 80%

D:  >= 50% and < 60%

F:  < 50%

The breakdown of the grades are:

4 Assignments worth 15% Total

About 16 Laboratories worth 10% Total

Projects worth 10% Total

In class quizzes worth 10% Total

Chapter online quizzes worth 5%

Midterm exams worth 20% Total

Final Exam worth 30%

## Question 2

### a.

```{r}
ddt = read.csv("DDT.csv")
m=with(ddt, as.numeric(factor(MILE)))
coplot(LENGTH~WEIGHT|RIVER*SPECIES, col=m, data=ddt)
```

### b

The lower left three plots show the length vs weight plots for CCatfish in the 
FCM, LCM and SCM rivers from left to right respectively. 

### c

Line A uses the as.numeric function to convert the vector MILE to numeric values.
The factor function factors the miles in order to reduce how many different 
possible values exist. This keeps the colors on the graph more uniform.

### d

Line B simply outputs how many unique values exist in m, which are the numbers 
produced from line A.

### e

The top 6 plots are empty because there aren't any LMBass or SMBuffalo in rivers
other than TRM. So no data plots belong in those boxes. 

### f

```{r}
fcm_cat = subset(ddt, RIVER=="FCM" & SPECIES=="CCATFISH",)
mean(fcm_cat$DDT)
```

## Question 3

a. Length of maximum span (feet) QUANTITATIVE

b. Number of vehicle lanes QUANTITATIVE

c. Toll bridge (yes or no) QUALITATIVE

d. Average daily traffic QUANTITATIVE

e. Condition of deck (good, fair, or poor) QUALITATIVE

f. Bypass or detour length (miles) QUANTITATIVE

g. Route type (interstate, U.S., state, county, or city) QUALITATIVE

## Question 4

### a. 

Simple: Simple Random Sample

Complex: stratified random sampling, cluster sampling, and systematic sampling

### b.

Simple Random Sample: A sample selected from a population in a way that every
different sample size has an equal chance of selection.

Stratified random sampling: Used when the samples can be split up based on 
certain strata that can help to see categorical similarities.

cluster sampling: This is used when it's more logical to sample natural 
groupings experimental units first, then collect data from all experimental units
within a cluster.

systematic sampling: Involves systematically selecting every k-th experimental 
unit from a list of all experimental units. 

## Question 5

```{r}
mtbe = read.csv("MTBE.csv")
ind = sample(1:223, 5, replace=FALSE)
mtbe[ind,]
```

```{r}
mtbeo = na.omit(mtbe)
depth=mtbeo[mtbeo$Aquifier=="Bedrock",]$Depth 
sd(depth)
```

## Question 6

```{r}
eq = read.csv("EARTHQUAKE.csv")
# dim(eq)
indEq = sample(1:2929, 30, replace=FALSE)
eq[indEq,]
```

```{r}
plot(ts(eq$MAG))
median(eq$MAG)
```


## Question 7

### a. What is the data collection method? 

Stratified Random Sample

### b. What is the population?

All the fish in the Tennessee River and its tributaries.

### c. Give the names of all the qualitative variables.

River and Species

## Question 8

### a. 

Bar Plot

### b. 

The variable is if the robot had legs, wheels, both or not. 

### c. 

The main design is legs only.

### d. 

```{r}
freq=c(15,8,63,20)
RL=c("None","Both","LegsO","WheelsO")
l=rep(RL,freq)
l
```

### e.

```{r}

pareto <- function(x, mn = "Pareto barplot", ...) {  # x is a vector
  x.tab = table(x)
  xx.tab = sort(x.tab, decreasing = TRUE, index.return = FALSE)
  cumsum(as.vector(xx.tab)) -> cs
  length(x.tab) -> lenx
  bp <- barplot(xx.tab, ylim = c(0,max(cs)),las = 2)
  lb <- seq(0,cs[lenx], l = 11)
  axis(side = 4, at = lb, labels = paste(seq(0, 100, length = 11), "%", sep = ""), las = 1, line = -1, col = "Blue", col.axis = "Red")
  for(i in 1:(lenx-1)){
    segments(bp[i], cs[i], bp[i+1], cs[i+1], col = i, lwd = 2)
  }
  title(main = mn, ...)
}


pareto(l)
```

## Question 9

### a.

```{r}
freq2=c(32, 6, 12)
RL2=c("Windows","Explorer","Office")
l2=rep(RL2,freq2)
pie(freq2, labels = RL2)
```

Explorer had the lowest proportion of security issues in 2012.

### b.

```{r}
freq2=c(6, 8, 22, 3, 11)
RL2=c("DOS","Info Disclosure","Remote Code Execution","Spoofing", "Privilege elevation")
l2=rep(RL2,freq2)
pareto(l2)
```


Based on these results, I'd advise Microsoft to tackle Remote Code Execution. 

## Question 10

```{r}
library(plotrix)
swd=read.csv("SWDEFECTS.csv", header=TRUE) 
head(swd)
library(plotrix) 
tab=table(swd$defect) 
rtab=tab/sum(tab) 
round(rtab,2)
pie3D(rtab,labels=list("OK","Defective"),main="pie plot of SWD")
```

According to the pie chart, there is only a 10% of chance of software having defective code within it. 

## Question 11

### Problem 2.72

# Come back to 11 a

a. 

```{r}
old<-subset(volt,subset=LOCATION=="OLD")
old$VOLTAGE->vto
vto
max(vto)
min(vto)
lept<-min(vto)-0.05
rept<-max(vto)+0.05
rnge<-rept-lept
inc<-rnge/9
inc
seq(lept, rept,by=inc)->cl
cl
cvto<-cut(vto,breaks=cl)
old.tab=table(cvto)
barplot(old.tab,space=0,main="Frequency Histogram(OLD)",las=2)
```


```{r}
# volt = read.csv("VOLTAGE.csv")
# 
# o_volt <- filter(volt, volt$LOCATION=="OLD")
# 
# breaks <- seq(8, 10.6, length.out = 10)  # 9 intervals between 8 and 10.6
# 
# 
# # Create the groups
# o_volt$Group <- cut(o_volt$VOLTAGE, breaks = breaks, labels = FALSE)
# # breaks
# counts <- table(o_volt$Group)
# v <- prop.table(counts)
# v
# class_names <- paste("Int", 1:length(counts))
# #
# # # Assign names to the relative frequencies vector
# names(relative_frequencies) <- class_names
# #
# # # names(v) <- counts
# barplot(v,space=0)
# 
# # Step 2: Calculate the relative frequency for each category
# # relative_freq <- prop.table(counts)
# # relative_freq
# # v =
# # hist()
```

### b.

```{r}
library(dplyr)
old_volt <- filter(volt, volt$LOCATION=="OLD")
stem(old_volt$VOLTAGE)
```

The stem and leaf plot is more informative because it shows the specific values of the decimals. 

### c.

```{r}
new<-subset(volt,subset=LOCATION=="NEW")
new$VOLTAGE->vtn
vtn
max(vtn)
min(vtn)
lept<-min(vtn)-0.05
rept<-max(vtn)+0.05
rnge<-rept-lept
inc<-rnge/9
inc
seq(lept, rept,by=inc)->cl
cl
cvtn<-cut(vtn,breaks=cl)
new.tab=table(cvtn)
barplot(new.tab,space=0,main="Frequency Histogram(NEW)",las=2)


```

### d.

Since a voltage reading of 9.2 is the cutoff between good and bad, the voltages measured in the new location are not as good as the old ones. In the old plot, it is clear that most readings met this requirement, but in the new plot only about half of the voltages are about 9.2 volts. 

### e.

### ADD MODE

Old:

```{r}
mean(old$VOLTAGE)
median((old$VOLTAGE))
# add mode

```

New:

```{r}
mean(new$VOLTAGE)
median(new$VOLTAGE)
```

The best measure of central tendency is the median because it doesn't allow any potential outliers to affect its value.

### f.

### g.

### h.

### i.

### j.

### k.

### l.

### m.

## Question 12

# Maybe change this?

```{r}
rough = c(1.72, 2.50, 2.16, 2.13, 1.06, 2.24, 2.31, 2.03, 1.09, 1.40, 2.57, 2.64, 1.26, 2.05, 1.19, 2.13, 1.27, 1.51, 2.41, 1.95)
t.test(rough, conf.level=0.95)
```

 {1.635802, 2.126198}


## Question 13

### a.

```{r}
gobi = read.csv("GOBIANTS.csv")
mean(gobi$AntSpecies)
median(gobi$AntSpecies)

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

getmode(gobi$AntSpecies)
```

### b.

I would recommend the median to describe the central tendency because the mean is very high due to a couple of large outliers. 
The mean is not an accurate representation of the data's middle ground.

### c.

```{r}
library(dplyr)
gob2 = within(gobi, 
                 {reg <- ifelse(Region == "Gobi Desert", "GS","DS")
                  reg<-factor(reg) # Make it a factor
                 })

dry = filter(gob2, reg=="DS")
mean(dry$PlantCov)
median(dry$PlantCov)
getmode(dry$PlantCov)
```

## d.

```{r}
desert = filter(gob2, reg=="GS")
mean(desert$PlantCov)
median(desert$PlantCov)
getmode(desert$PlantCov)
```

## e.

The center of the total plant coverage does appear to be different at the two regions. The coverage in the Gobi Desert is much lower than the coverage in the Dry Steppe. 


## Question 14

### a.

```{r}
galaxy = read.csv("GALAXY2.csv", header = TRUE)
sp = with(ddt, galaxy$VELOCITY)

summary(galaxy)

hist(galaxy$VELOCITY, main="Histogram of Veloctiy", xlab="Velocity")

```

The values of velocity range from 18499 to 24909. The median is 22355 and the mean is 21448. The histogram shows that move rescorded velocities were between 19,000 and 20,000 and between 22,000 and 23,000.

### b.

The histogram does support a double cluster theory due to having two separate ranges with high frequencies, instead of being a uniform graph.

### c.

```{r}
print("First Cluster")
A1775A <- filter(galaxy, VELOCITY < 21000)
mean(A1775A$VELOCITY)
median(A1775A$VELOCITY)
getmode(A1775A$VELOCITY)

print("Second Cluster")
A1775B <- filter(galaxy, VELOCITY >= 21000)
mean(A1775B$VELOCITY)
median(A1775B$VELOCITY)
getmode(A1775B$VELOCITY)
```
### d.

If the velocity is 20,000 km/s then it is most likely to belong to cluster A1775A. This is because that cluster's mean and median are both about 19,400 which is much closer than cluster B's.


## Question 15

```{r}
library(ggplot2)

ddt = read.csv("DDT.csv")
library(ggplot2)

g <- ggplot(data = ddt, aes(x = RIVER, y = LENGTH, fill = SPECIES, given = RIVER))
g <- g + geom_boxplot()
g <- g + ggtitle("Eid Zaben")
g


```

